:sectnums:
:toc2:

image::zhetapi-logo.png[]

image:https://semaphoreci.com/api/v1/vedavamadathil/zhetapi/branches/master/badge.svg[Build, link=https://semaphoreci.com/vedavamadathil/zhetapi]
image:https://app.codacy.com/project/badge/Grade/9df40090202d4fc1ba8a559fbe5f96a2[Quality, link=https://www.codacy.com/gh/vedavamadathil/zhetapi/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=vedavamadathil/zhetapi&amp;utm_campaign=Badge_Grade]

---

# Introduction

Zhetapi is a `C++17` ML and numerical analysis API that was built in the hopes of
making mathematical computation and algorithmic research more convenient to
users. In the name of convenience and beginner-friendliness, the API comes with a
scripting language, Zhetapi-lang.

This project is being developed on Unix environments (MacOS and Linux) and has
only been tested for them. It is a work in progress.

# Installation

Most of the features of Zhetapi depend only on `C++17` and the Boost library
(preferable version 1.65). CMake is used to compile the targets.

We recommend that you use the `g++-8` compiler, as it is the only one tested
so far.

*macOS (High Sierra and later)*

```
$ brew install gcc@8 boost cmake
```

*Ubuntu (18.04 and later)*

```
$ sudo apt-get install gcc-8 g++-8 libboost-dev cmake
```

Additional dependencies for image processing are `libpng`, `OpenGL` and `GLFW3`.
These are specifically used only for loading and displaying images.

To install the interpreter for Zhetapi-lang, run `./run.py install -j[THREADS=8]`
in the home directory of this repository. This is also compile the API libraries
(`libzhp.so`, `libzhpcuda.so` and `libzhp.a`) and the default Zhetapi-lang
libraries (`math` and `io` for now).

# Zhetapi-lang

Zhetapi-lang is a scripting language that on the surface appears to be very
similar to Python. However, there is much more focus on the mathematical and
notational aspects.

Current features include declaring variables (these include constant and
mathematical functions), looping (with `while` and `for`), importing libraries,
and defining and using algorithms.

A sample script is presented below:

```
# Single-line comments are alike to Python and Bash

# This is how you would import a library
import math

# Note the simplicity in defining mathematical functions
f(x) = x^3 + x * sin(x)

if (f(10) >= 0)
	println("f(10) = ", f(10))
else
	println("f(10) is less than 0")

i = 0
while (i++ < 10)
	println("[i = ", i, "] f(i) = ", f(i))

# Note the distinction between functions and algorithms
# An algorithm is like the Python equivalent of a function,
# and functions are like Python lambdas (but more convenient :))
alg myalg()
{
	x = 42
	println("x = ", x)
}
```

This scripting language is designed to make it easier to test and implement
algorithms in ML and numerical analysis. Get started with the interpreter with
`zhetapi -h`:

```
Usage: zhetapi [options] file...
Options:
 -c		Compiles the files into a single library.
 -d		Displays exported symbols in the libraries specified.
 -h		Display the guide for the interpreter.
 -o <file>	Place the compiled library into <file>.
 -L <directory>	Add <directory> to the interpreter's library search path
```

# Features

## Evaluation of Complex Expressions

The library can evaluate complex expressions, which have operands of various
types, such as integers, rational numbers, complex numbers, vectors and
matrices.

Through the RTTI mechanism of C++, the framework of the library allows the
evaluation to be sensitive to certain types of operands and their corresponding
operations. For example, multiplication of two integers yields an integer, the
division of two rational numbers stays rational, and the product of a matrix,
whose components are integers, with a rational scalar, yields a matrix with
rational components.

The `expression.h` header contains `expr()` and `exprf()`, which return
the value of the passed expression as a string. The difference in these two lies
in the fact that `exprf()` takes in a formatted string, while `expr()`
takes a string object.

```cpp
// Not formatted, prints "1.0"
cout << expr("1 + 2!/2.0") << endl;

// Formatted, also prints "1.0"
cout << exprf("%d + %d!/2.0", 1, 2) << endl;
```

## Usage and Declaration of Variables

The library provides constructs that allow the user to store variables and
retrieve them in the scope of the `Barn` class. Users can then refer to these
variables, and their values can be retrieved or changed.

```cpp
Variable <double> x {"x", 46};

Barn <double, int> brn;

brn.add(x);

// Prints "[x] - 46"
cout << brn.get("x") << endl;

// Generates an exception
cout << brn.get("y") << endl;
```

## User Defined Functions

Users can create mathematical functions, which can then be used as any other C++
functor object.

```cpp
Function <double, int> f = "f(x) = x^2";

// Prints "10"
cout << f(10) << endl;

// Prints "9/16"
cout << f(Rational <int> {3, 4}) << endl;

// Prints "25.0"
cout << f(5.0) << endl;
```

## Calculus

An object of class `Function` can be differentiated in terms of any of its
variables, to get its gradients and such. This process is symbolic, which has
the advantage that one has a closed form for the derivative, but the
disadvantage that it could be very complicated.

```cpp
Function f = "f(x) = x^2";

// Compute df/dx
Function df = f.derivative();

// Prints "f(x) = x^2"
cout << f << endl;

// Prints "df/dx(x) = 2x"
cout << df << endl;

// Prints "df/dx(2) = 4" twice
cout << "df/dx(2) = " << f.differentiate(2) << endl;
cout << "df/dx(2) = " << df(2) << endl;
```

## Machine Learning

Along with providing many mathematical utilities, Zhetapi also provides
machine learning capabilities. Currently, Zhetapi provides a `NeuralNetwork`
class that user can use to train deep neural networks on data sets.

### Construction of Models
Deep neural networks can be initialized in three ways. The first and canonical
method is as follows:

```cpp
model = zhetapi::NeuralNetwork <double> ({
	{2, new zhetapi::ml::Linear <double> ()},
	{5, new zhetapi::ml::Sigmoid <double> ()},
	{5, new zhetapi::ml::ReLU <double> ()},
	{2, new zhetapi::ml::ReLU <double> ()}
}, []() {return rand()/(double) RAND_MAX;});
```

Users can customize the model by specifying the number of neurons in each
layer and the activation to use.

Users can also load models from save files:

```cpp
model.load("model-save.out");
```

The file `model-save.out` must adhere to a specific binary format, that is
automated with the `NeuralNetwork::save` method:

```cpp
old.save("model-save.out");
```

Finally, users can load the structure of a model using a JSON file:

```cpp
model.load_json("model.json");
```

The file `model.json` must be in a structure similar to the following:

```json
{
    "Layers" : [
			{
            "Neurons": 784,
            "Activation": {
		    "Name": "Linear",
		    "Arguments": [1]
	    }
        },

        {
            "Neurons": 30,
            "Activation": {
		    "Name": "Sigmoid",
		    "Arguments": []
	    }
        },

        {
            "Neurons": 10,
            "Activation": {
		    "Name": "Softmax",
		    "Arguments": []
	    }
        }
    ]
}
```

### Using the Models

With C++ operator overloading, using the
neural network is as easy as calling it as a function:

```cpp
// Initialize weights randomly
model.randomize();

cout << model({3, 5}) << endl;
cout << model({4, 5}) << endl;
```

### Training the Models

Training is also very simple:

```cpp
// Create the cost function
zhetapi::ml::Erf <double> *opt = new zhetapi::ml::MeanSquaredError <double> ();

model.set_cost(opt);

/* Run a training session of 10 epochs
 * with ins as the set of inputs and outs
 * as the set of ouputs, with batches of
 * size 250 and an initial learning rate of 0.1.
 *
 * Runs with 8 threads, as specified in the template
 * parameter.
 */
model.train_epochs <8> (ins, outs, 10, 250, 0.1);
```

Note that the `NeuralNetwork::train_epochs` method takes a template parameter.
This parameter indicates how many threads are to be used to train the model.

Support for NVIDIA GPUs is granted with the Zhetapi library's `cuda` branch.
Training on these GPUs is as simple as follows:

```cpp
// The critique function: determines when two outputs are equivalent
// Note that it must be defined on the device, using the __device__ attribute
auto crit = [] __device__ (zhetapi::Vector <double> actual,
	zhetapi::Vector <double> expected) {
		return actual == expected;
};

model.cuda_epochs(ins, outs, 10, 250, 0.1, crit);
```

For a more comprehensive and practical example, see the `samples/mnist`
directory, in which we train a deep neural network to recognize hand written
digits from the MNIST data set.

## Linear Algebra

The library also provides ways in which the user can do linear algebra. The
classes `Vector` and `Matrix` come with a variety of methods on their own, which
include performing computation as well as manipulation of their representations.

# Modules

A description of each directory is presented below:

|===

| Directory | Description

| engine | Contains the library template headers. All library features are
present in this module. It will later contain API functions.

| engine/core | Contains the core API of the Zhetapi library, that runs behind
the scenes of the convenient features provided by the library.

| engine/cuda | Contains CUDA headers for the CUDA functions provided by the
library (Note: this has not been updated since around v0.2).

| engine/graph | Contains python scripts to assist in graphing procedures.

| engine/json | Contains nlohmann's single header C++ API for parsing JSON files.

| samples | Contains examples of library usage. Currently contains the `zhp`
directory for scripts and library samples and the `mnist` directory for a showcase
of the `NeuralNetwork` class.

| source | Contains source code for the headers, CLI, tests and upcoming
features of this library.

|===

# What Next?

## Simplification of Functions

Currently, objects of the `Function` class lack the complete ability to simplify
their representations. Some of this functionality does already exist, such as
the fact that adding/subtracting by 0 and multiplying/dividing by 1 are trivial
actions.

As an example, it is not yet possible to have the object recognize that `3xy +
5yx` is the same as `8xy`. This feature would also help reduce the complexity of
derivatives of these objects.

## Integration and Differentiation

Symbolic differentiation is a current feature. However, integration is not. This
feature will be implemented as soon as the current framework has been properly
placed. The addition of other kinds of differentiation and integration, such as
automatic differentiation, and different types of numerical integration
(quadrature, etc.), is also something to look forward to.

## Exact Forms of Numbers

One recognizes, simply by looking at the first few digits, that the number
`3.141592` is most nearly pi, and that the number `2.7182817` is most nearly
Euler's number. The hope is that at some point, the library will be able to
reach similar conclusions, through the help of integer relations algorithms such

## More Extensive Support for Machine Learning

Deep neural networks are already present in the Zhetapi library. The next steps
would be implementing convolutional networks, recurrent networks, and other structures
used in supervised learning. In addition, structures and algorithms used in unsupervised
learning and other branches of AI shall also be added.

# References

Below is a list of resources used in the making of this project.

 . Strang, Gilbert. _Introduction to Linear Algebra._ Wellesley, MA: Cambridge Press, 2016. Print.
 . Apostol, Tom M. _Calculus. Volume I_ New York: J. Wiley, 1967. Print.
 . Apostol, Tom M. _Calculus. Volume II_ Waltham, Mass: Blaisdell Pub. Co, 1967. Print.
 . Graham, Ronald L., Donald E. Knuth, and Oren Patashnik. _Concrete Mathematics
 : A Foundation For Computer Science._ Reading, Mass: Addison-Wesley, 1994. Print.
 . Stroustrup, Bjarne. _The C++ Programming Language._ Upper Saddle River, NJ: Addison-Wesley, 2013. Print.
 . Press, William H., et al. _Numerical Recipes : The Art of Scientific Computing._ Cambridge, UK New York: Cambridge University Press, 2007. Print.
 . Géron, Aurélien. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow : concepts, tools, and techniques to build intelligent systems. Sebastopol, CA: O'Reilly Media, Inc, 2019. Print.
